# manually run with "gcloud builds submit --config ./ci/cloudbuild-tiles.yaml --timeout=2000 --substitutions _LAYER_ID="fire.burned_area",_DATASET_ID="esacci.FIRE.mon.L4.BA.MODIS.Terra.MODIS_TERRA.v5-1.r1",_VARIABLE_ID="burned_area",_VERSION=0.0.1 ."
steps:
  - name: gcr.io/cloud-builders/gsutil
    id: 'download-netcdfs'
    entrypoint: '/bin/bash'
    args:
      - "-c"
      - "mkdir /data/netcdfs && gsutil -m cp -r gs://esa-cfs-cate-data/${_LAYER_ID}/1981.nc /data/netcdfs/"

  - name: gcr.io/esa-climate-from-space/cate:latest
    id: 'cate-export-data-cube'
    entrypoint: '/bin/bash'
    args:
      - "-c"
      - "conda run -n cate-env python data/write-zarr.py --layer ${_LAYER_ID} --variable ${_VARIABLE_ID} --output /data/dataset.zarr"

  - name: gcr.io/esa-climate-from-space/xcube:latest
    id: 'xcube-generate-full-images'
    entrypoint: '/bin/bash'
    args:
      - "-c"
      - "conda run -n xcube xcube tile --verbose --config ./style.yaml --style cfs --output /data/images /data/dataset.zarr"

  - name: v4tech/imagemagick
    id: 'imagemagick-resize'
    entrypoint: '/bin/bash'
    args:
      - "./data/resize-images.sh"

  - name: geographica/gdal2:2.4.0
    id: 'gdal-generate-tiles'
    entrypoint: '/bin/bash'
    args:
       - "./data/gdal-tiles.sh"

  - name: gcr.io/esa-climate-from-space/tile-mover
    id: 'prepare-upload'
    entrypoint: '/bin/bash'
    args:
      - "./data/prepare-tile-upload.sh"
      - "${_VARIABLE_ID}"
      - "${_LAYER_ID}"

  - name: gcr.io/cloud-builders/gsutil
    id: 'upload-to-storage'
    args:
      - "-m"
      - "cp"
      - "-r"
      - "/data/upload/${_LAYER_ID}/*"
      - "gs://esa-cfs-tiles/${_VERSION}/${_LAYER_ID}/"

options:
  diskSizeGb: 50
  machineType: 'N1_HIGHCPU_32'
  volumes:
  - name: 'vol1'
    path: '/data'
