# manually run with "gcloud builds submit --config ./ci/cloudbuild-tiles.yaml --timeout=2000 --substitutions _VARIABLE_ID="burned_area",_DATASET_ID="esacci.FIRE.mon.L4.BA.MODIS.Terra.MODIS_TERRA.v5-1.r1",_TIME_RANGE="2010-01-01.2011-01-01",_TILE_SIZE=256 ."

steps:
  # export zarr file with cate
  - name: gcr.io/esa-climate-from-space/cate:latest
    args:
      - "/bin/bash"
      - "-c"
      - "conda run -n cate-env python data/export.py -d ${_DATASET_ID} -v ${_VARIABLE_ID} -t ${_TIME_RANGE} -o ./dataset.zarr"
  # generate tiles from zarr
  - name: gcr.io/esa-climate-from-space/xcube:latest
    args:
      - "/bin/bash"
      - "-c"
      - "conda run -n xcube xcube tile --verbose --tile-size ${_TILE_SIZE} --output ./tmp/tiles --config ./style.yaml --style cci ./dataset.zarr"
  # generate one big global image from zarr
  - name: gcr.io/esa-climate-from-space/xcube:latest
    args:
      - "/bin/bash"
      - "-c"
      - "conda run -n xcube xcube tile --verbose --tile-size 2048,1024 --output ./tmp/full --config ./style.yaml --style cci ./dataset.zarr"
  # generate metadata file for layer
  - name: node:12
    entrypoint: 'node'
    args:
      - "./data/generate-metadata.js"
      - "${_VARIABLE_ID}"
  # prepare the upload folder
  - name: gcr.io/esa-climate-from-space/tile-mover
    args:
      - "data/prepare-tile-upload.sh"
      - "${_VARIABLE_ID}"
  # upload tiles into bucket
  - name: gcr.io/cloud-builders/gsutil
    args:
      - "-m"
      - "cp"
      - "-r"
      - "./upload/*"
      - "gs://esa-cfs-tiles/generated/${_VARIABLE_ID}/"
timeout: 2000s
